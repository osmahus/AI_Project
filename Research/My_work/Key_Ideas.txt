use https://timm.fast.ai/ (timm) to download SOTA pre-trained models directly and working with them
https://github.com/ShivamRajSharma/Vision-Transformer/blob/master/engine.py



from: First Principles of Computer Vision
https://www.youtube.com/watch?v=jJd0jpku8qs&list=PL2zRqk16wsdoz4eycyq7EmeV2KpE6JN76&index=5

Image Features Extraction in 2D includes the following:
1) Edge Detection
2) Corner Detection
3) Boundary from Edge Detection
4) 2D recognition using interesting points==> SIFT (Scale Invariant Feature Transform) Detector
5) Image alignment and stitching
6) Face Detection

Image Perception:
1) Image Segmentation
2) Object Tracking
3) Appearance Matching ==> Object Detection using PCA 



for TORCH.NN.FUNCTIONAL.SCALED_DOT_PRODUCT_ATTENTION make sure to disable is_casual



model_type = "vit"
add_extra_epochs = True  # if True then continue for extra epochs from the starting epoch
# If True load a pretrained model, and start_epoch = epoch of the model . Else if False then start_epoch = 0
start_from_model = False

# Wavelet Packet Transform Hyper Parameters
wpt_fun = 'db2'
wpt_level = 2
wpt_format = "Stack_ImgUseSameSize"
wpt_ch = ((2**wpt_level)**2)
img_and_wpt_channels = 3+wpt_ch
print(img_and_wpt_channels)

img_size = 32  # Input image height/width in pixels
patch_size = 8 # The height/width of a patch in pixels (patch is a slice of an image)

image_patch_flat_size = img_and_wpt_channels*patch_size**2 #3 Channels x height x width
embed_size = image_patch_flat_size
mlp_dim = 384 # dim of the last mlp classifier

down-scaling_factor=(2, 2, 2, 1) # used for swin

train_batch_size = 256 # https://www.youtube.com/watch?v=Owm1H0ukjS4
valid_batch_size = 256

num_classes = 2
encoder_depth = 9
attention_heads = 12

n_extra_epochs = 400
max_epochs = 200

base_lr = 0.005         # Base Learning rate 0.1 for SGD , 0.0001 for Adam
momentum = 0.9          # Momentum for SGD
weight_decay = 0.03     # Weight decay for Adam

loss_algo = CrossEntropyLoss

optimize_algo = SGD
optimize_args = {"lr": base_lr,
                #  "weight_decay": weight_decay,
                #  "momentum": momentum  # comment momentum for Adam
                 }

use_scheduler = False
schedule_algo = CosineAnnealingLR
schedule_args = {"T_max": delta_epochs}


# https://www.youtube.com/watch?v=HEUhSbD4P5c&list=PLbMVogVj5nJRY7X-tMNDHPGdmfZyfHC7J&index=2
01) Haar mentioned that one can crate continuous function using discontinuous function
02) This idea became important while we are digitizing continuos signals (Audio , Images) using bits
03) For example in images we discretize the original continuous signal to pixels
04) Pixel is a picture element includes the average intensity of the image in this position
05) Piecewise constant representation of the original image continuous signal is represented using a 2 dimensional sequence of pixels
06) this is called Piecewise constant representation
07) the smaller the pixel area -> the better the resolution
08) Dilation and Translation of epsi(t) captures the signal features
09) DYADIC Wavelet (Dilates by Powers of 2 to go from any resolution to the next resolution)
10) Haar wavelet is an example of DYADIC
11) Multi-Resolution Analysis "MRA" (Lader of Spaces): 
    On one direction go from coarse space to finer subspaces, on the other direction go from coarse space to coarser subspaces.
12) As an analogy , we are peeling off shell by shell using different dilates (from one resolution to the next) and translates(inside the same Resolution)
13) Focal Point: Piecewise Constant approximation on unit intervals. inside each unit interval, the signal is represented by its average inside that unit interval.
14) A set of functions forms a linear space if it's closed under linear combinations:
    i.e. a any linear operation on any of these functions results in a new function in the same space.
15) Linear operations includes: adding two functions, multiplying two functions, multiplying by constant.
16) we call the space V, and gives it subscript notation m , means its interval period is 2^(-m) = 1/(2^m)
17) Space V0 has interval 1 , space V1 has interval (1/2) , space V2 has interval (1/4)
18) The space ladder means that: 
    downwards <= .... V(-1) ⊂ V0 ⊂ V1 ⊂ V2 .... => upwards
19) using Phi(t) of Haar (1 from t= 0 to 1 , and 0 elsewhere) represents an orthonormal basis 
20) 
21) 
22) 

Intuitive Understanding vs Rigorous Understanding


https://www.youtube.com/watch?v=VXwXkME9uWU&list=PLMn2aW3wpAtOqo0g0OnHndXB1LnYBeMaX
01) a norm is the mathematical word for length of a vector
02) the norm in a vector space V is a mapping (mapping= function)
  || . || : V -> R such that 
  ||v|| >= 0  , for all V
  ||v|| = 0 <=> v = 0
  ||cv|| = |c| ||v|| , for and c in C(complex numbers set) amd all v in v
  ||v+w|| <= ||v|| + ||w|| , for all v , w in v (Triangle inequality)
03) a sequence vk shall converge to v as k approaches infinity
04) a W subset of V, is called a subspace if W itself a vector space.
